{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Guided Project: Exploring Hacker News Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're exploring the prime time on Hacker News to see when's the best time for the QnA platform `Ask HN` and `Show HN` is gonna be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by reading the clean data `hacker_news.csv`, you can download it by going to the menu bar and click `File -> Open -> hacker_news.csv -> File -> Download`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file   = reader(opened_file)\n",
    "hn          = list(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to separate the header (first row) to analyze all-data in `hn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "headers     = hn[0]\n",
    "hn          = hn[1:]\n",
    "print(headers)\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize: `Ask HN`, `Show HN`, and `others`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the data, there are 3 categories of we categorize the posts: `Ask HN`, `Show HN` (two of these posts start with the respective words) and `others`. We can group them by making 3 empty lists and append each data to respective groups. We can use a built-in function `lower()` so that we don't need to worry about the capitalization and `startswith()` to identify the first sentence of the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "18938\n"
     ]
    }
   ],
   "source": [
    "ask_posts   = []\n",
    "show_posts  = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    \n",
    "    # To match the strings, we can use a \n",
    "    # built-in function called `lower()`\n",
    "    if title.lower().startswith('ask hn') :\n",
    "        ask_posts.append(row)\n",
    "    if title.lower().startswith('show hn') :\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "## TROUBLESHOOTING:\n",
    "## BE AWARE OF WHAT YOU'RE APPENDING.\n",
    "### Previously, you're appending the `title`.\n",
    "### Hence, you get error in the codes after, \n",
    "### since you're adding the strings--not the num of comments.\n",
    "#### SOLVED: ...append(title) changed into ...append(row)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `avg` in `ask_posts` and `show_posts`\n",
    "We can get the number of comments on both lists `ask_posts` and `show_posts` as written below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of comments in `ask_posts` are 24483\n",
      "The average number of comments in `show_posts` are 14.038417431192661\n",
      "The number of comments in `show_posts` are 11988\n",
      "The average number of comments in `show_posts are 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "## `avg_ask_comments`\n",
    "total_ask_comments = 0\n",
    "\n",
    "for post in ask_posts:\n",
    "    num_comments        = int(post[4])\n",
    "    total_ask_comments += num_comments\n",
    "\n",
    "print('The number of comments in `ask_posts` are', total_ask_comments)\n",
    "\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print('The average number of comments in `show_posts` are', avg_ask_comments)    \n",
    "    \n",
    "## `avg_show_comments`\n",
    "total_show_comments = 0\n",
    "    \n",
    "## `avg_show_comments`\n",
    "for post in show_posts:\n",
    "    num_comments         = int(post[4])\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "print('The number of comments in `show_posts` are', total_show_comments)\n",
    "\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print('The average number of comments in `show_posts are', avg_show_comments)\n",
    "\n",
    "## A bit problem here: For some reason the file we're opening\n",
    "## are different with what DataQuest wants. I'm working on it.\n",
    "\n",
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the fact above, we can tell that `show_posts` list have more number of comments in average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data: PrimeTime!\n",
    "Now we've got the average numbers, we can look at the times people put `ask_posts`. We'll start by importing a `datetime` module, and make a list of list called `result_list` to input specifically **the time** and **number of comments**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "[['8/16/2016 9:55', 6], ['11/22/2015 13:43', 29], ['5/2/2016 10:14', 1], ['8/2/2016 14:20', 3], ['10/15/2015 16:38', 17]]\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for post in ask_posts:\n",
    "    \n",
    "    created_at   = post[6]\n",
    "    num_comments = int(post[4])\n",
    "    \n",
    "    result_list.append([created_at, num_comments])\n",
    "\n",
    "print(len(result_list))\n",
    "print(result_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we make two dictionaries so we can operate the average num of comments in this list *AND* sort the top 5 prime-time✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n",
      "{'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n"
     ]
    }
   ],
   "source": [
    "counts_by_hour   = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "date_format = '%m/%d/%Y %H:%M'\n",
    "\n",
    "for row in result_list:\n",
    "    \n",
    "    created_at   = row[0]\n",
    "    num_comments = row[1]\n",
    "    \n",
    "    ## Parse the time with the pre-defined `date_format`\n",
    "    time = dt.datetime.strptime(created_at, date_format)\n",
    "    \n",
    "    ## And then extract the `hour`\n",
    "    hour = time.strftime(\"%H\")\n",
    "    \n",
    "    if hour not in counts_by_hour :\n",
    "        counts_by_hour[hour]    = 1\n",
    "        comments_by_hour[hour]  = num_comments\n",
    "    else:\n",
    "        counts_by_hour[hour]   += 1\n",
    "        comments_by_hour[hour] += num_comments\n",
    "        \n",
    "print(counts_by_hour)\n",
    "print(comments_by_hour)\n",
    "\n",
    "# Problem: All output is reckoned to `01` and nothing else. \n",
    "## Whyyy? I'm figuring it out.\n",
    "\n",
    "## ANSWER: Look at the result from the list. \n",
    "## '...' and \"...\" IS DIFFERENT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply `avg_by_hour` = (comments / counts), and sort it based on the avg_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['09', 5.5777777777777775], ['13', 14.741176470588234], ['10', 13.440677966101696], ['14', 13.233644859813085], ['16', 16.796296296296298], ['23', 7.985294117647059], ['12', 9.41095890410959], ['17', 11.46], ['15', 38.5948275862069], ['21', 16.009174311926607], ['20', 21.525], ['02', 23.810344827586206], ['18', 13.20183486238532], ['03', 7.796296296296297], ['05', 10.08695652173913], ['19', 10.8], ['01', 11.383333333333333], ['22', 6.746478873239437], ['08', 10.25], ['04', 7.170212765957447], ['00', 8.127272727272727], ['06', 9.022727272727273], ['07', 7.852941176470588], ['11', 11.051724137931034]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "    avg = comments_by_hour[hour] / counts_by_hour[hour]\n",
    "#   avg = round(avg,3)\n",
    "    avg_by_hour.append([hour, avg])\n",
    "    \n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We swap the sequence of list since the built-in function `sorted()` is going to sort the **first** value on the list, while what we're sorting is in the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38.5948275862069, '15'], [23.810344827586206, '02'], [21.525, '20'], [16.796296296296298, '16'], [16.009174311926607, '21'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [13.20183486238532, '18'], [11.46, '17'], [11.383333333333333, '01'], [11.051724137931034, '11'], [10.8, '19'], [10.25, '08'], [10.08695652173913, '05'], [9.41095890410959, '12'], [9.022727272727273, '06'], [8.127272727272727, '00'], [7.985294117647059, '23'], [7.852941176470588, '07'], [7.796296296296297, '03'], [7.170212765957447, '04'], [6.746478873239437, '22'], [5.5777777777777775, '09']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "    \n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "print(sorted_swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00:00: 38.59 average comments per post\n",
      "02:00:00: 23.81 average comments per post\n",
      "20:00:00: 21.52 average comments per post\n",
      "16:00:00: 16.80 average comments per post\n",
      "21:00:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "\n",
    "for avg, hr in sorted_swap[:5]:\n",
    "    ## Yes. We can do this.\n",
    "    # 1. The template string could be put in straight away,\n",
    "    # 2. And we can directly parse and format in a line, as in\n",
    "    #        dt.datetime.strptime(hr, '%H').strftime('%H:%M')\n",
    "    #  make it a format of time ^           ^ and make a new format of it. \n",
    "    \n",
    "    #        v #1         vv #2\n",
    "    print(\n",
    "        \"{}:00: {:.2f} average comments per post\".format(\n",
    "            dt.datetime.strptime(hr, '%H').strftime('%H:%M'), avg    \n",
    "         )\n",
    "    )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the top 5 hours for `ask_posts` comments include 15:00, 02:00, 20:00, 16:00, and 21:00. Customer support, keep an eye on the prime time, okay? Things are gonna be busy at those times 👍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
